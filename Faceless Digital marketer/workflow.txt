This n8n workflow is connected to a Faceless Content Creator Telegram Bot, and whenever a message is sent to the Bot, the workflow is triggered. A custom code node then extracts the user's request from the message, which is sent to an AI Model to Create an enriched and very much detailed video prompt. After this, a custom code node is used to generate an ID for the current task. The previously generated video prompt is then sent to Kling AI using piapi for cheaper video generation cost, a wait time is set for about 5 minutes for the video to be completely generated, after this, the video URL is retrieved from piapi. The next node is a basic LLM chain which will generate a voice over text using the video's prompt, this text is then converted to speech using playai-tts via Groq API for free, the audio is then saved to cloudinary for easy accessiblity by other APIs. The video url from piapi and the voice over audio url from cloudinary are then sent to json2video to join both of them in an mp4 file. A wait time of about 1-3 minutes is set for this to happen, after which the joined video is gotten from json2video and the next node  adds a caption to the video, which is simply the voice over text showing on the screen at every speech instance. There is a wait for about 1 minutes for the final file to be ready, then proceed to get the captioned video from json2video. Google Gemini then generate a social media caption for the post using every related information from the previous nodes, the video ID, url and string type of data are then appended to the row of a google sheets for tracking. The summary of the content is then sent back to the telegram user, including its caption, video url and the video file itself. Saving the video data to google sheets triggers a zapier workflow that gets the video scheduled to social media accounts using buffer.